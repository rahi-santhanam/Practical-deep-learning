{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2aFzCPmXoKa"
   },
   "source": [
    "#### \n",
    "NAME: RAHINI DEVI S\n",
    "\n",
    "ROLL NO: 225229129\n",
    "\n",
    "PDL_Lab-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\2mscdsa18\\appdata\\roaming\\python\\python310\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\2mscdsa18\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\2mscdsa18\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V93vdGIHWZaD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "import numpy as np     \n",
    "import nltk\n",
    "from nltk.corpus import stopwords   \n",
    "from sklearn.model_selection import train_test_split       \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   \n",
    "from tensorflow.keras.models import Sequential     \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   \n",
    "from tensorflow.keras.models import load_model   \n",
    "import re\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zCReSC0WobP0",
    "outputId": "f400b2bb-eca2-452e-8ca7-56d28ed1f3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\2mscdsa18\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "hna1AROTq7zI",
    "outputId": "61ab3d53-9dd2-4b26-fd28-42a1a1c1122f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0        [one, reviewers, mentioned, watching, oz, epis...\n",
      "1        [a, wonderful, little, production, the, filmin...\n",
      "2        [i, thought, wonderful, way, spend, time, hot,...\n",
      "3        [basically, family, little, boy, jake, thinks,...\n",
      "4        [petter, mattei, love, time, money, visually, ...\n",
      "                               ...                        \n",
      "49995    [i, thought, movie, right, good, job, it, crea...\n",
      "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [i, catholic, taught, parochial, elementary, s...\n",
      "49998    [i, going, disagree, previous, comment, side, ...\n",
      "49999    [no, one, expects, star, trek, movies, high, a...\n",
      "Name: review, Length: 50000, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('IMDB Dataset.csv')\n",
    "    x_data = df['review']     \n",
    "    y_data = df['sentiment']  \n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          \n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)    \n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops]) \n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "    return x_data, y_data\n",
    "x_data, y_data = load_dataset()\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "rpYHsaMOrXwK",
    "outputId": "82693008-f3f2-4847-81b8-97999d5e9d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "5047     [if, went, movie, see, huge, academy, award, p...\n",
      "48828    [i, also, viewed, film, santa, barbara, film, ...\n",
      "40308    [as, far, i, recall, balanchine, alterations, ...\n",
      "781      [i, thought, movie, incredible, i, absolutely,...\n",
      "6326     [pilot, mitch, macafee, jeff, morrow, sees, uf...\n",
      "                               ...                        \n",
      "35509    [i, first, saw, movie, years, ago, i, shocked,...\n",
      "24551    [it, second, year, academy, already, voting, p...\n",
      "20204    [anyone, new, incredibly, prolific, takashi, m...\n",
      "18385    [the, thing, i, knew, film, prior, seeing, rob...\n",
      "18923    [you, might, tempted, rent, film, peter, selle...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "12332    [this, film, opened, poor, showings, first, we...\n",
      "47046    [it, really, great, film, able, ignore, blake,...\n",
      "18175    [cia, analyst, douglas, freeman, gyllenhaal, g...\n",
      "11316    [this, last, film, trilogy, brilliant, turkish...\n",
      "5286     [paul, bettany, great, role, tortured, father,...\n",
      "                               ...                        \n",
      "29625    [frankly, i, met, real, han, su, ying, seeing,...\n",
      "1165     [although, low, budget, film, clearly, last, m...\n",
      "10950    [i, shakespeare, lover, since, childhood, i, a...\n",
      "21053    [my, wife, i, watched, marvelous, movie, eveni...\n",
      "13770    [this, movie, leave, thinking, while, many, pe...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "5047     1\n",
      "48828    1\n",
      "40308    1\n",
      "781      1\n",
      "6326     0\n",
      "        ..\n",
      "35509    1\n",
      "24551    0\n",
      "20204    1\n",
      "18385    1\n",
      "18923    0\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "12332    1\n",
      "47046    1\n",
      "18175    1\n",
      "11316    1\n",
      "5286     1\n",
      "        ..\n",
      "29625    0\n",
      "1165     1\n",
      "10950    0\n",
      "21053    1\n",
      "13770    1\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c5S3yT6LsssB"
   },
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "IeI8I5jBrhqg",
    "outputId": "c2092caf-18f2-4886-c597-4f0cbbcc1824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[  54  320    3 ...    0    0    0]\n",
      " [   1   22 2082 ...    0    0    0]\n",
      " [ 109  135    1 ...    0    0    0]\n",
      " ...\n",
      " [ 154   81  872 ...    0    0    0]\n",
      " [   2   65    1 ...  728 4477 1245]\n",
      " [  98  140 5768 ...    0    0    0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[    8     4  2881 ...  8407  8206  2658]\n",
      " [    7    15    21 ...     0     0     0]\n",
      " [ 3845 19211  2057 ...   280   247   952]\n",
      " ...\n",
      " [    1  1591  1339 ...    74    52    22]\n",
      " [  218   223     1 ...     0     0     0]\n",
      " [    8     3   467 ...   173  3151   586]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    }
   ],
   "source": [
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "max_length = get_max_length()\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "total_words = len(token.word_index) + 1   \n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "S2n3umyVsDRZ",
    "outputId": "c71fbff6-d279-4f8e-ac3d-1c3bada7b238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 130, 32)           2953120   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,982,177\n",
      "Trainable params: 2,982,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jWHCQWXys3PL",
    "outputId": "46c5bc25-1ee0-40f5-e86e-6c4067d37136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 32s 93ms/step - loss: 0.4582 - accuracy: 0.7573\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 0.1978 - accuracy: 0.9264\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 0.1151 - accuracy: 0.9619\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 0.0663 - accuracy: 0.9784\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 28s 89ms/step - loss: 0.0501 - accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 28s 91ms/step - loss: 0.0418 - accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 0.0237 - accuracy: 0.9936\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.0376 - accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.0262 - accuracy: 0.9923\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.0250 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d47af3e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "szQCB945vjAS",
    "outputId": "0f0f65fd-04ec-4157-f03b-2da7d495add1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 13ms/step - loss: 0.5745 - accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5745013952255249, 0.8689000010490417]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6nsy8kSWuFpW",
    "outputId": "ece5add3-c1d0-45d8-d7ac-1611947adb34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 130, 32)           2953120   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,967,777\n",
      "Trainable params: 2,967,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model1.add(LSTM(32))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "bKr2_XwJuNfk",
    "outputId": "33555784-b52a-40c0-b9ce-1fdc257048b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 26s 72ms/step - loss: 0.4676 - accuracy: 0.7452\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 0.1990 - accuracy: 0.9258\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 0.1065 - accuracy: 0.9643\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.0633 - accuracy: 0.9795\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 23s 73ms/step - loss: 0.0437 - accuracy: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d37d4b370>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pooonVpkwUG6",
    "outputId": "737eb5de-383e-4d61-9ede-00e86d888927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 130, 32)           2953120   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              49664     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,011,105\n",
      "Trainable params: 3,011,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model2.add(Bidirectional(LSTM(LSTM_OUT)))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "HwwFXnGnwjzg",
    "outputId": "d3c50663-b41e-4989-ef85-244dd8e0b0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 45s 128ms/step - loss: 0.3832 - accuracy: 0.8190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d3cbdf400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size = 128)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
